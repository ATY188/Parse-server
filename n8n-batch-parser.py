"""
n8n æ‰¹æ¬¡è™•ç†è…³æœ¬ (Python ç‰ˆæœ¬)
ç”¨é€”ï¼šæ‰¹æ¬¡è§£æ n8n ç”¢å‡ºçš„æ–‡ç« åˆ—è¡¨

ä½¿ç”¨æ–¹å¼ï¼š
python n8n-batch-parser.py input.json output.json

è¼¸å…¥æ ¼å¼ (input.json)ï¼š
[
  {"url": "https://example.com/article1", "id": "001"},
  {"url": "https://example.com/article2", "id": "002"}
]
"""

import sys
import json
import asyncio
import httpx
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
import os

# è¨­å®š
API_URL = os.getenv('PARSER_API_URL', 'http://localhost:3000/api/parse')
DELAY_MS = int(os.getenv('DELAY_MS', '2000'))
MAX_RETRIES = int(os.getenv('MAX_RETRIES', '3'))

print('ğŸ“‹ n8n æ‰¹æ¬¡æ–‡ç« è§£æå™¨ (Python ç‰ˆæœ¬)')
print('=' * 60)
print(f'ğŸ”— API ç«¯é»: {API_URL}')
print(f'â±ï¸  è«‹æ±‚é–“éš”: {DELAY_MS}ms')
print(f'ğŸ”„ æœ€å¤§é‡è©¦: {MAX_RETRIES} æ¬¡\n')


async def parse_article(
    client: httpx.AsyncClient,
    article_data: Dict[str, Any],
    retry_count: int = 0
) -> Dict[str, Any]:
    """
    è§£æå–®ä¸€æ–‡ç« 
    
    Args:
        client: httpx å®¢æˆ¶ç«¯
        article_data: æ–‡ç« è³‡æ–™ï¼ˆåŒ…å« urlï¼‰
        retry_count: ç•¶å‰é‡è©¦æ¬¡æ•¸
        
    Returns:
        è§£æçµæœ
    """
    try:
        response = await client.post(
            API_URL,
            json={'url': article_data['url']},
            timeout=30.0
        )
        
        if response.status_code != 200:
            raise Exception(f"HTTP {response.status_code}: {response.text}")
        
        result = response.json()
        
        if result.get('success'):
            return {
                **article_data,
                'success': True,
                'parsed_data': result['data'],
                'parsed_at': datetime.now().isoformat()
            }
        else:
            raise Exception('è§£æå¤±æ•—')
            
    except Exception as e:
        print(f"âŒ è§£æå¤±æ•— (ç¬¬ {retry_count + 1} æ¬¡): {article_data['url']}")
        print(f"   éŒ¯èª¤: {str(e)}")
        
        # é‡è©¦é‚è¼¯
        if retry_count < MAX_RETRIES:
            print(f"   â³ ç­‰å¾… {DELAY_MS * 2}ms å¾Œé‡è©¦...")
            await asyncio.sleep((DELAY_MS * 2) / 1000)
            return await parse_article(client, article_data, retry_count + 1)
        
        return {
            **article_data,
            'success': False,
            'error': str(e),
            'failed_at': datetime.now().isoformat()
        }


async def batch_parse(input_file: str, output_file: str):
    """
    æ‰¹æ¬¡è™•ç†æ–‡ç« 
    
    Args:
        input_file: è¼¸å…¥æª”æ¡ˆè·¯å¾‘
        output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    """
    try:
        # è®€å–è¼¸å…¥æª”æ¡ˆ
        input_path = Path(input_file)
        if not input_path.exists():
            print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”æ¡ˆ: {input_file}")
            sys.exit(1)
        
        with open(input_path, 'r', encoding='utf-8') as f:
            input_data = json.load(f)
        
        if not isinstance(input_data, list):
            print('âŒ è¼¸å…¥æª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼šå¿…é ˆæ˜¯é™£åˆ—')
            sys.exit(1)
        
        print(f'ğŸ“¥ è¼‰å…¥ {len(input_data)} ç¯‡æ–‡ç« å¾…è§£æ\n')
        
        results = []
        success_count = 0
        fail_count = 0
        
        # å»ºç«‹ HTTP å®¢æˆ¶ç«¯
        async with httpx.AsyncClient() as client:
            # é€ä¸€è™•ç†æ¯ç¯‡æ–‡ç« 
            for i, article in enumerate(input_data):
                progress = f"[{i + 1}/{len(input_data)}]"
                
                print(f"{progress} ğŸ” è§£æä¸­: {article['url']}")
                
                result = await parse_article(client, article)
                results.append(result)
                
                if result['success']:
                    success_count += 1
                    parsed_data = result['parsed_data']
                    title = parsed_data.get('title', 'ç„¡æ¨™é¡Œ')
                    word_count = parsed_data.get('word_count', 0)
                    author = parsed_data.get('author', 'æœªçŸ¥')
                    
                    print(f"{progress} âœ… æˆåŠŸ: {title}")
                    print(f"{progress}    å­—æ•¸: {word_count}, ä½œè€…: {author}")
                else:
                    fail_count += 1
                    print(f"{progress} âŒ å¤±æ•—")
                
                # é¿å…è«‹æ±‚éå¿«ï¼ˆæœ€å¾Œä¸€å€‹ä¸éœ€è¦å»¶é²ï¼‰
                if i < len(input_data) - 1:
                    await asyncio.sleep(DELAY_MS / 1000)
                
                print()  # ç©ºè¡Œåˆ†éš”
        
        # å„²å­˜çµæœ
        output_path = Path(output_file)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print('=' * 60)
        print('âœ¨ æ‰¹æ¬¡è™•ç†å®Œæˆï¼')
        print(f'ğŸ“Š çµ±è¨ˆè³‡è¨Š:')
        print(f'   ç¸½è¨ˆ: {len(input_data)} ç¯‡')
        print(f'   æˆåŠŸ: {success_count} ç¯‡ ({success_count/len(input_data)*100:.1f}%)')
        print(f'   å¤±æ•—: {fail_count} ç¯‡ ({fail_count/len(input_data)*100:.1f}%)')
        print(f'\nğŸ’¾ çµæœå·²å„²å­˜è‡³: {output_file}')
        
        # å¦‚æœæœ‰å¤±æ•—çš„é …ç›®ï¼Œå¦å¤–å„²å­˜å¤±æ•—æ¸…å–®
        if fail_count > 0:
            failed_items = [r for r in results if not r['success']]
            failed_file = str(output_path).replace('.json', '-failed.json')
            
            with open(failed_file, 'w', encoding='utf-8') as f:
                json.dump(failed_items, f, ensure_ascii=False, indent=2)
            
            print(f'âš ï¸  å¤±æ•—é …ç›®å·²å„²å­˜è‡³: {failed_file}')
        
    except Exception as e:
        print(f'\nâŒ æ‰¹æ¬¡è™•ç†ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
        sys.exit(1)


def main():
    """ä¸»ç¨‹å¼"""
    if len(sys.argv) < 3:
        print('ä½¿ç”¨æ–¹å¼ï¼š')
        print('  python n8n-batch-parser.py <è¼¸å…¥æª”æ¡ˆ.json> <è¼¸å‡ºæª”æ¡ˆ.json>')
        print('')
        print('ç¯„ä¾‹ï¼š')
        print('  python n8n-batch-parser.py articles.json results.json')
        print('')
        print('ç’°å¢ƒè®Šæ•¸ï¼š')
        print('  PARSER_API_URL - Parser API ä½å€ï¼ˆé è¨­: http://localhost:3000/api/parseï¼‰')
        print('  DELAY_MS - è«‹æ±‚é–“éš”æ¯«ç§’æ•¸ï¼ˆé è¨­: 2000ï¼‰')
        print('  MAX_RETRIES - æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼ˆé è¨­: 3ï¼‰')
        print('')
        print('è¼¸å…¥æª”æ¡ˆæ ¼å¼ï¼š')
        print('  [')
        print('    {"url": "https://example.com/article1", "id": "001"},')
        print('    {"url": "https://example.com/article2", "id": "002"}')
        print('  ]')
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2]
    
    # åŸ·è¡Œæ‰¹æ¬¡è™•ç†
    asyncio.run(batch_parse(input_file, output_file))


if __name__ == '__main__':
    main()

